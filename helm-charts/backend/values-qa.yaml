replicas: 5
restartPolicy: Always
deploymentName: back-end
image_port_number: 1199

#TODO -> Deployment Annotations :: https://seifrajhi.github.io/blog/reloader-configmap-secret/
#TODO -> You shouldn’t have to manually restart pods when a ConfigMap or Secret changes.
#TODO ->  Reloader is a Kubernetes controller that automatically triggers rolling upgrades for Deployments, StatefulSets, DaemonSets, and other workloads when their associated ConfigMaps or Secrets change, eliminating the need for manual pod restarts.
annotations:
  reloader.stakater.com/auto: "true"   #✅
  reloader.stakater.com/search: "true" # This annotation tells Reloader to only trigger rolling upgrades when changes occur in ConfigMaps or Secrets that are explicitly annotated with reloader.stakater.com/match: “true”
  configmap.reloader.stakater.com/reload: "foo-configmap" # Specifying specific ConfigMap or Secret to trigger rolling upgrade
  secret.reloader.stakater.com/reload: "test-secret"

configMap:
  enabled: false
  name: database-configmap
  annotations:
    reloader.stakater.com/auto: "true" #✅
    reloader.stakater.com/match: "true"

#TODO ==> AKS DATABASE KEY VAULT STO
secrets:
  enabled: true
  name: db-azure-key-vault
  provider: azure
  tenantId: "736437467324673467346374"
  keyVaultName: "7364374673246734rerer346374"  #TODO -> Name of your Azure Key Vault.
  managedIdentity:
    clientId: "73643746732467346f54374"
  KeySecrets:
    - objectName: "db-password" #TODO -> Name of the secret in Key Vault.
      objectType: "secret"      #TODO -> secret, key, or cert.
    - objectName: "db-username"
      objectType: "secret"



service:
  serviceApp: backend-service
  types: NodePort
  targetPort: 1199
  port: 80

app:
  env: dev

image:
  repository: srinu641/spring-application-k8s
  tag: v3.0
  pullPolicy: IfNotPresent

container:
  containerName: springbootcontainer # container name must be lower case
  port: 1199

resources:
  requests:
    cpu: 400m
    memory: 64Mi
  limits:
    cpu: 500m
    memory: 356Mi

strategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 3
    maxUnavailable: 0

namespace:
  enabled: true
  name: qa-namespace

PersistentVolumeClaim:
  enabled: true
  name: aks-dynamic-pvc
  storage: 50Gi

#TODO -> ReadWriteMany access mode, allowing multiple Pods across different nodes to access the same data.
#TODO ->  file.csi.azure.com: This driver is better suited for shared application data and stateful applications requiring file-level sharing
serviceAccount:
  enabled: true
  automount: true
  annotations: {}
  name: backend-azure-blob-aks-storage
  provisioner:  blob.csi.azure.com #TODO -> file.csi.azure.com
  reclaimPolicy: Delete #TODO -> Retain
  volumeBindingMode: WaitForFirstConsumer #TODO -> Immediate | WaitForFirstConsumer: Binding is delayed until a pod that uses the PVC is scheduled
  skuName: Premium_LRS
  azureStorageAuthType: ManagedIdentity
  allowVolumeExpansion: true

HaProxy:
  enabled: true
  name: ha-proxy-deployment
  ingressClassName: haproxy
  rules:
     host: viveja.com
  annotations:
    haproxy.org/ingress.class: "haproxy"
    haproxy.org/rate-limit-requests: "10"
    haproxy.org/rate-limit-period: 1s
    haproxy.org/rate-limit-status-code: "429"
    haproxy.org/rate-limit-size: "1000000"
    haproxy.org/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rewrite-target: /v1/$2
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    qos.projectcalico.org/egressBandwidth: 100M
    qos.projectcalico.org/egressBurst: 200M

MinPodDisruptionBudget:
  enabled: true
  name: backend-pdb-min
  minAvailable: 3

MaxPodDisruptionBudget:
  enabled: true
  name: backend-pdb-max
  maxUnavailable: 7

NamespaceFinalizers:
  enabled: false
  name: namespace-finalizers

CornJob:
  enabled: false
  name: cron-job-back-end
  schedule: "0 7 * * *"        # Daily at 7 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 10
  failedJobsHistoryLimit: 3
  restartPolicy: OnFailure
  env:
    runcronjob: "true"


hpa:
  enabled: true
  minReplicas: 1
  maxReplicas: 25
  name: backend-hpa

keda:
  enabled: true

resourceQuota:
  enabled: false
  name: quota-with-limits
  hard:
    replicas: "100"
    requestsCpu: "1"
    requestsMemory: "4Gi"
    limitsCpu: "3"
    limitsMemory: "8Gi"

limitRange:
  enabled: false
  name: limit-range
  container:
    max:
      cpu: "2"
      memory: "2Gi"
    min:
      cpu: "800m"
      memory: "500Mi"
    default:
      cpu: "1"
      memory: "1Gi"
    defaultRequest:
      cpu: "500m"
      memory: "500Mi"


livenessProbe:
  httpGet:
    path: /actuator/health/liveness
    port: 1199
  initialDelaySeconds: 10
  periodSeconds: 15
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /actuator/health/readiness
    port: 1199
  initialDelaySeconds: 5
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

nodeSelector: { }
tolerations: [ ]
affinity: { }

initContainers:
  - name: wait-for-mysql
    image: mysql:8.0
    command:
      - sh
      - -c
      - |
        echo "Waiting for MySQL to be ready..."
        until mysqladmin ping \
          -h "$DB_HOST" \
          -u "$DB_USER" \
          -p"$DB_PASSWORD" \
          --silent; do
          echo "MySQL not ready, retrying..."
          sleep 5
        done
        echo "MySQL is ready!"

securityContext:
  runAsNonRoot: true
  readOnlyRootFilesystem: true
  runAsUser: 1000
  privileged: false

networkPolicy:
  enabled: true
  name: application-network-policy
  podSelector:
    matchLabels:
      app: app-label
  ingress:
    enabled: true
  egress:
    enabled: true

---